{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jennifer Camacho, Octavia Larentis and Lauren Picado - 18 May, 2019\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Robust Principal Component Analysis (RPCA) for detecting Moving Foreground in a Video Sequence\n",
    "### Implemented with the Principal Component Pursuit (PCP) and Stable Principal Component Pursuit (SPCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and visualization\n",
    "from glob import glob\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('..')))\n",
    "import scipy.misc\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import tkinter\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image, ImageTk\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Statistical Analysis\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCPA Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCP-RPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_pcp(M, lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"pcp\"):\n",
    "              \n",
    "    # Define a maximum number of iterations\n",
    "    maximumIterations=1000\n",
    "    # Frame size\n",
    "    height, width = M.shape\n",
    "    # Set all empty values to 0\n",
    "    tmp = np.isnan(M)\n",
    "    M[tmp] = 0\n",
    "    \n",
    "    # Prepare a low-rank matrix to store background output\n",
    "    L = np.zeros((height, width))  \n",
    "    # Prepare a sparse matrix to store the moving object \n",
    "    S = np.zeros((height, width))\n",
    "   \n",
    "    dual_variable = np.zeros((height, width)) # Dualvar update\n",
    "    \n",
    "    # Set default penalty term lambda\n",
    "    if lambda0 == \"default\":\n",
    "        lambda0 = 1/np.sqrt(max(height, width)) * float(1)\n",
    "        \n",
    "    # Set defaults\n",
    "    mu0 = 0.25/np.abs(M).mean()\n",
    "\n",
    "    # Open log files for convergence criteria\n",
    "    f = open(convergenceLog + \"_ds.txt\", \"a\")\n",
    "    g = open(convergenceLog + \"_dl.txt\", \"a\")\n",
    "        \n",
    "    for iterations in range(0, maximumIterations):\n",
    "        \n",
    "        # Current Euclidean distance between the sparse and low-rank matrix\n",
    "        euclid = np.linalg.norm(np.concatenate((S,L), axis=1), 'fro')              \n",
    "        temp_X = dual_variable / mu0 + M\n",
    "        temp_Y = temp_X - S;\n",
    "        \n",
    "        # Note the change to the current low-rank and sparse matrices\n",
    "        change_L = L;   \n",
    "        change_S = S\n",
    "        temp_U, temp_sigma, temp_V = np.linalg.svd(temp_Y, full_matrices=False);\n",
    "        \n",
    "        # Calculate matrix rank\n",
    "        matrixRank = (temp_sigma > 1/mu0).sum()\n",
    "        sigma_iter = np.diag(temp_sigma[0:matrixRank] - 1/mu0)\n",
    "        \n",
    "        # Iterative update of the low-rank matrix\n",
    "        L = np.dot(np.dot(temp_U[:,0:matrixRank], sigma_iter), temp_V[0:matrixRank,:])\n",
    "        \n",
    "        # Update change to low-rank matrix\n",
    "        change_L = L - change_L\n",
    "        \n",
    "        temp_Y = temp_X - L\n",
    "        S = soft_threshold(temp_Y, lambda0/mu0)\n",
    "        change_S = S - change_S\n",
    "        \n",
    "        # Dualvar change\n",
    "        temp_Z = M - S - L\n",
    "        temp_Z[tmp] = 0\n",
    "        dual_variable = dual_variable + mu0 * temp_Z;\n",
    "        \n",
    "        # Check whether the convergence condition has been met\n",
    "        stoppingCriterion = np.linalg.norm(np.concatenate((change_S, change_L), axis=1), 'fro') / (euclid + 1)\n",
    "        \n",
    "        # Log the current state of low-rank and sparse matrices\n",
    "        f.write(np.array2string(change_S))\n",
    "        g.write(np.array2string(change_L))\n",
    "         \n",
    "        # Terminate if the convergence criterion has been reached\n",
    "        if stoppingCriterion < convergenceTolerance: \n",
    "            break\n",
    "    \n",
    "    # Close log files\n",
    "    f.close()\n",
    "    g.close()\n",
    "    \n",
    "    return L, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPCP-RPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_spcp(M, lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"spcp\"):\n",
    "    \n",
    "    # Define a maximum number of iterations\n",
    "    maximumIterations=1000\n",
    "    # Frame size\n",
    "    height, width = M.shape\n",
    "    # Default mu\n",
    "    mu0 = np.sqrt(2 * max(height, width))\n",
    "    # Set penalty lambda\n",
    "    if lambda0==\"default\":\n",
    "        lambda0 = 1.0 / np.sqrt(max(height, width))\n",
    "        \n",
    "    tmp_L = np.zeros((height, width)) \n",
    "    tmp_S = np.zeros((height, width))\n",
    "    \n",
    "    # Prepare a low-rank matrix to store background output\n",
    "    L = np.zeros((height, width))\n",
    "    # Prepare a sparse matrix to store the moving object \n",
    "    S = np.zeros((height, width))\n",
    "    \n",
    "    threshold_0 = 1\n",
    "    threshold_1 = 1\n",
    "    mu_iteration = mu0\n",
    "    currentIteration = 1\n",
    "    \n",
    "    # Open log files for convergence criteria\n",
    "    f = open(convergenceLog + \"_ds.txt\", \"a\")\n",
    "    g = open(convergenceLog + \"_dl.txt\", \"a\")\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        temp_Y_L = L + (threshold_0-1)/threshold_1*(L - tmp_L)\n",
    "        temp_Y_S = S + (threshold_0-1)/threshold_1*(S - tmp_S)\n",
    "        temp_G_L = temp_Y_L - 0.5*(temp_Y_L + temp_Y_S - M)\n",
    "        \n",
    "        # Use the Python numpy package for singular vector decomposition\n",
    "        temp_U, temp_sigma, temp_V = np.linalg.svd(temp_G_L, full_matrices=False);\n",
    "        \n",
    "        # Calculate matrix rank\n",
    "        matrixRank = (temp_sigma > mu_iteration/2).sum()\n",
    "        sigma_iter = np.diag(temp_sigma[0:matrixRank] - mu_iteration/2)\n",
    "        \n",
    "        # Update change to low-rank matrix\n",
    "        tmp_L = L\n",
    "        L = np.dot(np.dot(temp_U[:,0:matrixRank], sigma_iter), temp_V[0:matrixRank,:])\n",
    "        temp_G_S = temp_Y_S - 0.5*(temp_Y_L + temp_Y_S - M)\n",
    "        \n",
    "        # Update change to sparse matrix\n",
    "        tmp_S = S\n",
    "        S = soft_threshold(temp_G_S, lambda0*mu_iteration/2)\n",
    "        threshold_1, threshold_0 = (np.sqrt(threshold_1**2+1) + 1)/2, threshold_1\n",
    "        \n",
    "        # Check against convergence tolerance\n",
    "        change_L =2*(temp_Y_L - L) + (L + S - temp_Y_L - temp_Y_S)\n",
    "        change_S =2*(temp_Y_S - S) + (L + S - temp_Y_L - temp_Y_S) \n",
    "        stoppingCriterion = np.sqrt(np.linalg.norm(change_L, ord='fro')**2 + np.linalg.norm(change_S, ord='fro')**2)\n",
    "        \n",
    "        # Log the current state of low-rank and sparse matrices\n",
    "        f.write(np.array2string(change_S))\n",
    "        g.write(np.array2string(change_L))\n",
    "        \n",
    "        if currentIteration >= maximumIterations or stoppingCriterion < convergenceTolerance:\n",
    "            break\n",
    "        else:\n",
    "            currentIteration += 1\n",
    "    \n",
    "    # Close log files  \n",
    "    f.close()\n",
    "    g.close()\n",
    "    \n",
    "    return L, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCP-RPCA with decreasing penalty parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_pcp_vary(M, lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"pcp_vary\"):\n",
    "     \n",
    "    # Define a maximum number of iterations\n",
    "    maximumIterations=1000\n",
    "    # Frame size\n",
    "    height, width = M.shape\n",
    "    tmp = np.isnan(M)\n",
    "    M[tmp] = 0\n",
    "    \n",
    "    # Prepare a sparse matrix to store the moving object \n",
    "    S = np.zeros((height, width))\n",
    "    # Prepare a low-rank matrix to store background output\n",
    "    L = np.zeros((height, width))\n",
    "    # Dualvar\n",
    "    dual_variable = np.zeros((height, width)) \n",
    " \n",
    "    # Set default mu\n",
    "    mu0 = 0.25/np.abs(M).mean()\n",
    "    \n",
    "    # Set penalty term lambda\n",
    "    if lambda0 == \"default\":\n",
    "        lambda0 = 1/np.sqrt(max(height, width)) * float(1)\n",
    "    \n",
    "    # Initiate the first mu term that will decrease with each iteration\n",
    "    mu_iter = min(10*mu0, 0.99*np.linalg.norm(M, ord='fro'))   \n",
    "    \n",
    "    # Eta\n",
    "    n = 0.8\n",
    "\n",
    "    # Open log files for convergence criteria\n",
    "    f = open(convergenceLog + \"_ds.txt\", \"a\")\n",
    "    g = open(convergenceLog + \"_dl.txt\", \"a\")\n",
    "       \n",
    "    for iterations in range(maximumIterations):\n",
    "        \n",
    "        # Current Euclidean distance between the sparse and low-rank matrix\n",
    "        euclid = np.linalg.norm(np.concatenate((S,L), axis=1), 'fro')   \n",
    "        \n",
    "        temp_X = dual_variable / mu_iter + M\n",
    "        temp_Y = temp_X - S;\n",
    "        \n",
    "        # Temporarily assign current low-rank matrix\n",
    "        change_L = L;       \n",
    "        temp_U, temp_sigma, temp_V = np.linalg.svd(temp_Y, full_matrices=False);\n",
    "        \n",
    "        # Calculate matrix rank\n",
    "        matrixRank = (temp_sigma > 1/mu_iter).sum()\n",
    "        sigma_iter = np.diag(temp_sigma[0:matrixRank] - 1/mu_iter)\n",
    "        \n",
    "        # Update the low-rank matrix \n",
    "        L = np.dot(np.dot(temp_U[:,0:matrixRank], sigma_iter), temp_V[0:matrixRank,:])\n",
    "        change_L = L - change_L\n",
    "        temp_Y = temp_X - L\n",
    "        change_S = S\n",
    "        \n",
    "        # Update the sparse matrix\n",
    "        S = soft_threshold(temp_Y, lambda0/mu_iter)\n",
    "        change_S = S - change_S\n",
    "\n",
    "        # Dual variable update\n",
    "        temp_Z = M - S - L\n",
    "        temp_Z[tmp] = 0\n",
    "        dual_variable = dual_variable + mu_iter * temp_Z;\n",
    "        \n",
    "        # Update mu each iteration\n",
    "        mu_iter = max(n*mu_iter, mu0)\n",
    "        \n",
    "        # Log the current state of low-rank and sparse matrices\n",
    "        f.write(np.array2string(change_S))\n",
    "        g.write(np.array2string(change_L))\n",
    "        \n",
    "        # Check against convergence tolerance\n",
    "        stoppingCriterion = np.linalg.norm(np.concatenate((change_S, change_L), axis=1), 'fro') / (euclid + 1)\n",
    "        \n",
    "        # Terminate if convergence has been reached\n",
    "        if stoppingCriterion < convergenceTolerance: \n",
    "            break\n",
    "    \n",
    "    # Close log files\n",
    "    f.close()\n",
    "    g.close()\n",
    "    \n",
    "    return L, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPCP-RPCA with decreasing penalty parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_spcp_vary(M, lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"spcp_vary\"):\n",
    "    \n",
    "    # Define a maximum number of iterations\n",
    "    maximumIterations=1000\n",
    "    # Frame size\n",
    "    height, width = M.shape\n",
    "    # Set default mu\n",
    "    mu = np.sqrt(2*max(height, width))\n",
    "    # Set default penalty term lambda\n",
    "    if lambda0==\"default\":\n",
    "        lambda0 = 1.0/np.sqrt(max(height, width))\n",
    "    \n",
    "    # Initiate the first mu term that will decrease with each iteration\n",
    "    mu0 = min(10*mu, 0.99*np.linalg.norm(M, ord='fro'))   \n",
    "    \n",
    "    # Eta\n",
    "    n = 0.8\n",
    " \n",
    "    temp_L = np.zeros((height, width)) \n",
    "    temp_S = np.zeros((height, width))\n",
    "    \n",
    "    # Prepare a low-rank matrix to store background output\n",
    "    L = np.zeros((height, width)) \n",
    "    # Prepare a sparse matrix to store the moving object\n",
    "    S = np.zeros((height, width))\n",
    "    \n",
    "    threshold_0 = 1\n",
    "    threshold_1 = 1\n",
    "    mu_iteration = mu0\n",
    "    currentIteration = 1\n",
    "    \n",
    "    # Open convergence log files\n",
    "    f = open(convergenceLog + \"_ds.txt\", \"a\")\n",
    "    g = open(convergenceLog + \"_dl.txt\", \"a\")\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        # Y _k for kth iteration\n",
    "        temp_Y_L = L + (threshold_0 - 1)/threshold_1*(L - temp_L)\n",
    "        temp_Y_S = S + (threshold_0 - 1)/threshold_1*(S - temp_S)\n",
    "    \n",
    "        temp_G_L = temp_Y_L - 0.5*(temp_Y_L + temp_Y_S - M)\n",
    "        \n",
    "        # Use the Python numpy package for singular vector decomposition\n",
    "        temp_U, temp_sigma, temp_V = np.linalg.svd(temp_G_L, full_matrices=False);\n",
    "        \n",
    "        # Calculate matrix rank\n",
    "        matrixRank = (temp_sigma > mu_iteration/2).sum()\n",
    "        sigma_iter = np.diag(temp_sigma[0:matrixRank] - mu_iteration/2)\n",
    "        temp_L = L\n",
    "        \n",
    "        # Update the low rank matrix\n",
    "        L = np.dot(np.dot(temp_U[:,0:matrixRank], sigma_iter), temp_V[0:matrixRank,:])\n",
    "        temp_G_S = temp_Y_S - 0.5*(temp_Y_L + temp_Y_S - M)\n",
    "        temp_S = S\n",
    "        \n",
    "        # Update the sparse matrix\n",
    "        S = soft_threshold(temp_G_S, lambda0*mu_iteration/2)\n",
    "        threshold_1, threshold_0 = (np.sqrt(threshold_1**2+1) + 1)/2, threshold_1\n",
    "        \n",
    "        # Update the mu term each iteration\n",
    "        mu_iteration = max(n*mu_iteration, mu)\n",
    "        \n",
    "        # Current changes to the sparse and low-rank matrices\n",
    "        change_L =2*(temp_Y_L - L) + (L + S - temp_Y_L - temp_Y_S)\n",
    "        change_S =2*(temp_Y_S - S) + (L + S - temp_Y_L - temp_Y_S) \n",
    "        \n",
    "        # Euclidean distance between updates to sparse and low-rank matrices\n",
    "        euclid = np.sqrt(np.linalg.norm(change_L, ord='fro')**2 + np.linalg.norm(change_S, ord='fro')**2)\n",
    "        \n",
    "        # Log the current state of low-rank and sparse matrices\n",
    "        f.write(np.array2string(change_S))\n",
    "        g.write(np.array2string(change_L))\n",
    "        \n",
    "        # Check against convergence tolerance\n",
    "        if currentIteration >= maximumIterations or euclid < convergenceTolerance:\n",
    "            break\n",
    "        else:\n",
    "            currentIteration += 1\n",
    "    \n",
    "    # Close convergence log files\n",
    "    f.close()\n",
    "    g.close()\n",
    "            \n",
    "    return L, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(inputs, mu0):\n",
    "    \n",
    "    # Check whether inputs is greater than mu operator\n",
    "    outputs = np.maximum(inputs - mu0, 0)\n",
    "    \n",
    "    # Increment output by the difference\n",
    "    outputs = outputs + np.minimum(inputs + mu0, 0)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMatrix(frames):\n",
    "    matrixVolume = []\n",
    "    \n",
    "    # Loop through frames and append to volume object\n",
    "    for frame in frames:\n",
    "        img = Image.open(frame).convert('L')\n",
    "        dat = list(img.getdata())\n",
    "        matrixVolume.append(dat)\n",
    "    \n",
    "    stackedFrames = np.array(matrixVolume)\n",
    "    \n",
    "    return stackedFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeImages(folder, filename, matrix, width, height):\n",
    "    \n",
    "    outputHeight, outputWidth = matrix.shape\n",
    "    \n",
    "    # Write individual frames for analysis\n",
    "    for i in range(outputHeight):\n",
    "        frame = matrix[i,:].reshape((width, height), order='F').transpose()   \n",
    "        cv2.imwrite(folder + 'bin' + str(i+1).zfill(6) + '.png', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeMask(folder, filename, matrix, width, height, out_threshold):\n",
    "    \n",
    "    outputHeight, outputWidth = matrix.shape\n",
    "    \n",
    "    # Create binary mask images\n",
    "    for i in range(outputHeight):\n",
    "        frame = matrix[i,:].reshape((width, height), order='F').transpose()\n",
    "        tmp = frame\n",
    "        \n",
    "        # Splice at desired binary threshold level to create masks\n",
    "        frame[tmp > out_threshold] = 255 \n",
    "        frame[tmp < out_threshold] = 0 \n",
    "        \n",
    "        # Write frames to a folder for statistical analysis\n",
    "        cv2.imwrite(folder + 'bin' + str(i+1).zfill(6) + '.png', frame)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergencePlot(convergence_ds, convergence_dl):\n",
    "    n = len(convergence_ds)\n",
    "    iteration_ds = np.arange(1,(n + 1))\n",
    "    m = len(convergence_dl)\n",
    "    iteration_dl = np.arange(1, (m + 1))\n",
    "    plt.figure(1)\n",
    "    plt.plot(iteration_ds,convergence_ds,'r.')\n",
    "    plt.figure(2)\n",
    "    plt.plot(iteration_dl,convergence_dl,'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Video Frames\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = map(lambda s: os.path.join(\"..\\\\highway\\\\\", s), os.listdir(\"..\\\\highway\\\\\"))\n",
    "highway = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestrian Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian\\\\\", s), os.listdir(\"..\\\\pedestrian\\\\\"))\n",
    "pedestrian = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = map(lambda s: os.path.join(\"..\\\\office\\\\\", s), os.listdir(\"..\\\\office\\\\\"))\n",
    "office = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Ground Truth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = map(lambda s: os.path.join(\"..\\\\highway_groundtruth\\\\\", s), os.listdir(\"..\\\\highway_groundtruth\\\\\"))\n",
    "highway_groundtruth = generateMatrix(join)\n",
    "\n",
    "try:\n",
    "    os.stat('..\\\\highway_G\\\\')\n",
    "except:\n",
    "    os.mkdir('..\\\\highway_G')\n",
    "\n",
    "# Fix ground truth, remove multi-level segmentation \n",
    "writeMask(\"..\\\\highway_G\\\\\", \"highway\", highway_groundtruth, 320, 240, 180)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\highway_G\\\\\", s), os.listdir(\"..\\\\highway_G\\\\\"))\n",
    "highway_g = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestrian Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian_groundtruth\\\\\", s), os.listdir(\"..\\\\pedestrian_groundtruth\\\\\"))\n",
    "pedestrian_groundtruth = generateMatrix(join)\n",
    "\n",
    "try:\n",
    "    os.stat('..\\\\pedestrian_G\\\\')\n",
    "except:\n",
    "    os.mkdir('..\\\\pedestrian_G')\n",
    "\n",
    "# Fix ground truth, remove multi-level segmentation \n",
    "writeMask(\"..\\\\pedestrian_G\\\\\", \"pedestrian\", pedestrian_groundtruth, 360, 240, 180)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian_G\\\\\", s), os.listdir(\"..\\\\pedestrian_G\\\\\"))\n",
    "pedestrian_g = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = map(lambda s: os.path.join(\"..\\\\office_groundtruth\\\\\", s), os.listdir(\"..\\\\office_groundtruth\\\\\"))\n",
    "office_groundtruth = generateMatrix(join)\n",
    "\n",
    "try:\n",
    "    os.stat('..\\\\office_G\\\\')\n",
    "except:\n",
    "    os.mkdir('..\\\\office_G')\n",
    "\n",
    "# Fix ground truth, remove multi-level segmentation \n",
    "writeMask(\"..\\\\office_G\\\\\", \"office\", office_groundtruth, 360, 240, 180)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\office_G\\\\\", s), os.listdir(\"..\\\\office_G\\\\\"))\n",
    "office_g = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCP-RPCA with fixed penalty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_pcp(np.transpose(highway), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"highway_pcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\highway_PCP_L\\\\', '..\\\\highway_PCP_S\\\\', '..\\\\highway_PCP_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\highway_PCP_L\\\\\", \"highway\", L.transpose(), 320, 240)\n",
    "writeImages(\"..\\\\highway_PCP_S\\\\\", \"highway\", S.transpose(), 320, 240)\n",
    "writeMask(\"..\\\\highway_PCP_S_mask\\\\\", \"highway\", S.transpose(), 320, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\highway_PCP_S_mask\\\\\", s), os.listdir(\"..\\\\highway_PCP_S_mask\\\\\"))\n",
    "highway_pcp = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2561755803805477\n",
      "0.3359580194452619\n",
      "0.2875275712935128\n",
      "0.23535352855228694\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "highway_recall_pcp = recall_score(highway_g, highway_pcp, average='samples')\n",
    "print(highway_recall_pcp)\n",
    "\n",
    "highway_precision_pcp = precision_score(highway_g, highway_pcp, average='samples')\n",
    "print(highway_precision_pcp)\n",
    "\n",
    "highway_fscore_pcp = f1_score(highway_g, highway_pcp, average='samples')\n",
    "print(highway_fscore_pcp)\n",
    "\n",
    "highway_cm_pcp = confusion_matrix(highway_g.ravel(), highway_pcp.ravel())\n",
    "highway_specificity_pcp = highway_cm_pcp[1,1]/(highway_cm_pcp[1,0] + highway_cm_pcp[1,1])\n",
    "print(highway_specificity_pcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestrian Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_pcp(np.transpose(pedestrian), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"pedestrian_pcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\pedestrian_PCP_L\\\\', '..\\\\pedestrian_PCP_S\\\\', '..\\\\pedestrian_PCP_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\pedestrian_PCP_L\\\\\", \"pedestrian\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\pedestrian_PCP_S\\\\\", \"pedestrian\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\pedestrian_PCP_S_mask\\\\\", \"pedestrian\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian_PCP_S_mask\\\\\", s), os.listdir(\"..\\\\pedestrian_PCP_S_mask\\\\\"))\n",
    "pedestrian_pcp = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01843289414464411\n",
      "0.06231186132499719\n",
      "0.028215133592309302\n",
      "0.018940769480705645\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "pedestrian_recall_pcp = recall_score(pedestrian_g, pedestrian_pcp, average='samples')\n",
    "print(pedestrian_recall_pcp)\n",
    "\n",
    "pedestrian_precision_pcp = precision_score(pedestrian_g, pedestrian_pcp, average='samples')\n",
    "print(pedestrian_precision_pcp)\n",
    "\n",
    "pedestrian_fscore_pcp = f1_score(pedestrian_g, pedestrian_pcp, average='samples')\n",
    "print(pedestrian_fscore_pcp)\n",
    "\n",
    "pedestrian_cm_pcp = confusion_matrix(pedestrian_g.ravel(), pedestrian_pcp.ravel())\n",
    "pedestrian_specificity_pcp = pedestrian_cm_pcp[1,1]/(pedestrian_cm_pcp[1,0] + pedestrian_cm_pcp[1,1])\n",
    "print(pedestrian_specificity_pcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_pcp(np.transpose(office), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"office_pcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\office_PCP_L\\\\', '..\\\\office_PCP_S\\\\', '..\\\\office_PCP_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\office_PCP_L\\\\\", \"office\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\office_PCP_S\\\\\", \"office\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\office_PCP_S_mask\\\\\", \"office\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\office_PCP_S_mask\\\\\", s), os.listdir(\"..\\\\office_PCP_S_mask\\\\\"))\n",
    "office_pcp = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12989686723829738\n",
      "0.2572727076836333\n",
      "0.16873578779927886\n",
      "0.12887607585528998\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "office_recall_pcp = recall_score(office_g, office_pcp, average='samples')\n",
    "print(office_recall_pcp)\n",
    "\n",
    "office_precision_pcp = precision_score(office_g, office_pcp, average='samples')\n",
    "print(office_precision_pcp)\n",
    "\n",
    "office_fscore_pcp = f1_score(office_g, office_pcp, average='samples')\n",
    "print(office_fscore_pcp)\n",
    "\n",
    "office_cm_pcp = confusion_matrix(office_g.ravel(), office_pcp.ravel())\n",
    "office_specificity_pcp = office_cm_pcp[1,1]/(office_cm_pcp[1,0] + office_cm_pcp[1,1])\n",
    "print(office_specificity_pcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPCP-RPCA with fixed penalty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_spcp(np.transpose(highway), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"highway_spcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\highway_SPCP_L\\\\', '..\\\\highway_SPCP_S\\\\', '..\\\\highway_SPCP_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\highway_SPCP_L\\\\\", \"highway\", L.transpose(), 320, 240)\n",
    "writeImages(\"..\\\\highway_SPCP_S\\\\\", \"highway\", S.transpose(), 320, 240)\n",
    "writeMask(\"..\\\\highway_SPCP_S_mask\\\\\", \"highway\", S.transpose(), 320, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\highway_SPCP_S_mask\\\\\", s), os.listdir(\"..\\\\highway_SPCP_S_mask\\\\\"))\n",
    "highway_spcp = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24619663378440432\n",
      "0.41876638861474524\n",
      "0.30160151984029476\n",
      "0.22174229212817387\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "highway_recall_spcp = recall_score(highway_g, highway_spcp, average='samples')\n",
    "print(highway_recall_spcp)\n",
    "\n",
    "highway_precision_spcp = precision_score(highway_g, highway_spcp, average='samples')\n",
    "print(highway_precision_spcp)\n",
    "\n",
    "highway_fscore_spcp = f1_score(highway_g, highway_spcp, average='samples')\n",
    "print(highway_fscore_spcp)\n",
    "\n",
    "highway_cm_spcp = confusion_matrix(highway_g.ravel(), highway_spcp.ravel())\n",
    "highway_specificity_spcp = highway_cm_spcp[1,1]/(highway_cm_spcp[1,0]+highway_cm_spcp[1,1])\n",
    "print(highway_specificity_spcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestrian Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_spcp(np.transpose(pedestrian), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"pedestrian_spcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\pedestrian_SPCP_L\\\\', '..\\\\pedestrian_SPCP_S\\\\', '..\\\\pedestrian_SPCP_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\pedestrian_SPCP_L\\\\\", \"pedestrian\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\pedestrian_SPCP_S\\\\\", \"pedestrian\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\pedestrian_SPCP_S_mask\\\\\", \"pedestrian\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian_SPCP_S_mask\\\\\", s), os.listdir(\"..\\\\pedestrian_SPCP_S_mask\\\\\"))\n",
    "pedestrian_spcp = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017545992586858062\n",
      "0.08119195840263553\n",
      "0.02860198030045817\n",
      "0.0180329122149806\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "pedestrian_recall_spcp = recall_score(pedestrian_g, pedestrian_spcp, average='samples')\n",
    "print(pedestrian_recall_spcp)\n",
    "\n",
    "pedestrian_precision_spcp = precision_score(pedestrian_g, pedestrian_spcp, average='samples')\n",
    "print(pedestrian_precision_spcp)\n",
    "\n",
    "pedestrian_fscore_spcp = f1_score(pedestrian_g, pedestrian_spcp, average='samples')\n",
    "print(pedestrian_fscore_spcp)\n",
    "\n",
    "pedestrian_cm_spcp = confusion_matrix(pedestrian_g.ravel(), pedestrian_spcp.ravel())\n",
    "pedestrian_specificity_spcp = pedestrian_cm_spcp[1,1]/(pedestrian_cm_spcp[1,0] + pedestrian_cm_spcp[1,1])\n",
    "print(pedestrian_specificity_spcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_spcp(np.transpose(office), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"office_spcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\office_SPCP_L\\\\', '..\\\\office_SPCP_S\\\\', '..\\\\office_SPCP_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\office_SPCP_L\\\\\", \"office\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\office_SPCP_S\\\\\", \"office\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\office_SPCP_S_mask\\\\\", \"office\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\office_SPCP_S_mask\\\\\", s), os.listdir(\"..\\\\office_SPCP_S_mask\\\\\"))\n",
    "office_spcp = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13617121852615657\n",
      "0.2742447810555182\n",
      "0.17691773175059056\n",
      "0.135385150200187\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "office_recall_spcp = recall_score(office_g, office_spcp, average='samples')\n",
    "print(office_recall_spcp)\n",
    "\n",
    "office_precision_spcp = precision_score(office_g, office_spcp, average='samples')\n",
    "print(office_precision_spcp)\n",
    "\n",
    "office_fscore_spcp = f1_score(office_g, office_spcp, average='samples')\n",
    "print(office_fscore_spcp)\n",
    "\n",
    "office_cm_spcp = confusion_matrix(office_g.ravel(), office_spcp.ravel())\n",
    "office_specificity_spcp = office_cm_spcp[1,1]/(office_cm_spcp[1,0] + office_cm_spcp[1,1])\n",
    "print(office_specificity_spcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCP-RPCA with decreasing penalty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_pcp_vary(np.transpose(highway), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"highway_pcp_vary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\highway_PCP_VARY_L\\\\', '..\\\\highway_PCP_VARY_S\\\\', '..\\\\highway_PCP_VARY_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\highway_PCP_VARY_L\\\\\", \"highway\", L.transpose(), 320, 240)\n",
    "writeImages(\"..\\\\highway_PCP_VARY_S\\\\\", \"highway\", S.transpose(), 320, 240)\n",
    "writeMask(\"..\\\\highway_PCP_VARY_S_mask\\\\\", \"highway\", S.transpose(), 320, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\highway_PCP_VARY_S_mask\\\\\", s), os.listdir(\"..\\\\highway_PCP_VARY_S_mask\\\\\"))\n",
    "highway_pcp_vary = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2560679795699915\n",
      "0.3360193914342377\n",
      "0.2874681844800135\n",
      "0.23523233030562157\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "highway_recall_pcp_vary = recall_score(highway_g, highway_pcp_vary, average='samples')\n",
    "print(highway_recall_pcp_vary)\n",
    "\n",
    "highway_precision_pcp_vary = precision_score(highway_g, highway_pcp_vary, average='samples')\n",
    "print(highway_precision_pcp_vary)\n",
    "\n",
    "highway_fscore_pcp_vary = f1_score(highway_g, highway_pcp_vary, average='samples')\n",
    "print(highway_fscore_pcp_vary)\n",
    "\n",
    "highway_cm_pcp_vary = confusion_matrix(highway_g.ravel(), highway_pcp_vary.ravel())\n",
    "highway_specificity_pcp_vary = highway_cm_pcp_vary[1,1]/(highway_cm_pcp_vary[1,0] + highway_cm_pcp_vary[1,1])\n",
    "print(highway_specificity_pcp_vary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestrian Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_pcp_vary(np.transpose(pedestrian), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"pedestrian_pcp_vary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\pedestrian_PCP_VARY_L\\\\', '..\\\\pedestrian_PCP_VARY_S\\\\', '..\\\\pedestrian_PCP_VARY_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\pedestrian_PCP_VARY_L\\\\\", \"pedestrian\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\pedestrian_PCP_VARY_S\\\\\", \"pedestrian\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\pedestrian_PCP_VARY_S_mask\\\\\", \"pedestrian\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian_PCP_VARY_S_mask\\\\\", s), os.listdir(\"..\\\\pedestrian_PCP_VARY_S_mask\\\\\"))\n",
    "pedestrian_pcp_vary = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01843289414464411\n",
      "0.062414346376454335\n",
      "0.028225553591356038\n",
      "0.018940769480705645\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "pedestrian_recall_pcp_vary = recall_score(pedestrian_g, pedestrian_pcp_vary, average='samples')\n",
    "print(pedestrian_recall_pcp_vary)\n",
    "\n",
    "pedestrian_precision_pcp_vary = precision_score(pedestrian_g, pedestrian_pcp_vary, average='samples')\n",
    "print(pedestrian_precision_pcp_vary)\n",
    "\n",
    "pedestrian_fscore_pcp_vary = f1_score(pedestrian_g, pedestrian_pcp_vary, average='samples')\n",
    "print(pedestrian_fscore_pcp_vary)\n",
    "\n",
    "pedestrian_cm_pcp_vary = confusion_matrix(pedestrian_g.ravel(), pedestrian_pcp_vary.ravel())\n",
    "pedestrian_specificity_pcp_vary = pedestrian_cm_pcp_vary[1,1]/(pedestrian_cm_pcp_vary[1,0] + pedestrian_cm_pcp_vary[1,1])\n",
    "print(pedestrian_specificity_pcp_vary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_pcp_vary(np.transpose(office), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"office_pcp_vary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\office_PCP_VARY_L\\\\', '..\\\\office_PCP_VARY_S\\\\', '..\\\\office_PCP_VARY_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "\n",
    "writeImages(\"..\\\\office_PCP_VARY_L\\\\\", \"office\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\office_PCP_VARY_S\\\\\", \"office\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\office_PCP_VARY_S_mask\\\\\", \"office\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\office_PCP_VARY_S_mask\\\\\", s), os.listdir(\"..\\\\office_PCP_VARY_S_mask\\\\\"))\n",
    "office_pcp_vary = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1296793615630713\n",
      "0.25729179290528553\n",
      "0.16856500762987742\n",
      "0.12866510033324544\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "office_recall_pcp_vary = recall_score(office_g, office_pcp_vary, average='samples')\n",
    "print(office_recall_pcp_vary)\n",
    "\n",
    "office_precision_pcp_vary = precision_score(office_g, office_pcp_vary, average='samples')\n",
    "print(office_precision_pcp_vary)\n",
    "\n",
    "office_fscore_pcp_vary = f1_score(office_g, office_pcp_vary, average='samples')\n",
    "print(office_fscore_pcp_vary)\n",
    "\n",
    "office_cm_pcp_vary = confusion_matrix(office_g.ravel(), office_pcp_vary.ravel())\n",
    "office_specificity_pcp_vary = office_cm_pcp_vary[1,1]/(office_cm_pcp_vary[1,0] + office_cm_pcp_vary[1,1])\n",
    "print(office_specificity_pcp_vary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPCP-RPCA with decreasing penalty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_spcp_vary(np.transpose(highway), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"highway_spcp_vary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\highway_SPCP_VARY_L\\\\', '..\\\\highway_SPCP_VARY_S\\\\', '..\\\\highway_SPCP_VARY_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "        \n",
    "writeImages(\"..\\\\highway_SPCP_VARY_L\\\\\", \"highway\", L.transpose(), 320, 240)\n",
    "writeImages(\"..\\\\highway_SPCP_VARY_S\\\\\", \"highway\", S.transpose(), 320, 240)\n",
    "writeMask(\"..\\\\highway_SPCP_VARY_S_mask\\\\\", \"highway\", S.transpose(), 320, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\highway_SPCP_VARY_S_mask\\\\\", s), os.listdir(\"..\\\\highway_SPCP_VARY_S_mask\\\\\"))\n",
    "highway_spcp_vary = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2460251341374694\n",
      "0.41960111416373613\n",
      "0.30164239244177776\n",
      "0.2215941609378051\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "highway_recall_spcp_vary = recall_score(highway_g, highway_spcp_vary, average='samples')\n",
    "print(highway_recall_spcp_vary)\n",
    "\n",
    "highway_precision_spcp_vary = precision_score(highway_g, highway_spcp_vary, average='samples')\n",
    "print(highway_precision_spcp_vary)\n",
    "\n",
    "highway_fscore_spcp_vary = f1_score(highway_g, highway_spcp_vary, average='samples')\n",
    "print(highway_fscore_spcp_vary)\n",
    "\n",
    "highway_cm_spcp_vary = confusion_matrix(highway_g.ravel(), highway_spcp_vary.ravel())\n",
    "highway_specificity_spcp_vary = highway_cm_spcp_vary[1,1]/(highway_cm_spcp_vary[1,0] + highway_cm_spcp_vary[1,1])\n",
    "print(highway_specificity_spcp_vary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestrian Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_spcp_vary(np.transpose(pedestrian), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"pedestrian_spcp_vary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\pedestrian_SPCP_VARY_L\\\\', '..\\\\pedestrian_SPCP_VARY_S\\\\', '..\\\\pedestrian_SPCP_VARY_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "        \n",
    "writeImages(\"..\\\\pedestrian_SPCP_VARY_L\\\\\", \"pedestrian\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\pedestrian_SPCP_VARY_S\\\\\", \"pedestrian\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\pedestrian_SPCP_VARY_S_mask\\\\\", \"pedestrian\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\pedestrian_SPCP_VARY_S_mask\\\\\", s), os.listdir(\"..\\\\pedestrian_SPCP_VARY_S_mask\\\\\"))\n",
    "pedestrian_spcp_vary = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-score, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017545992586858062\n",
      "0.08119195840263553\n",
      "0.02860198030045817\n",
      "0.0180329122149806\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "pedestrian_recall_spcp_vary = recall_score(pedestrian_g, pedestrian_spcp_vary, average='samples')\n",
    "print(pedestrian_recall_spcp_vary)\n",
    "\n",
    "pedestrian_precision_spcp_vary = precision_score(pedestrian_g, pedestrian_spcp_vary, average='samples')\n",
    "print(pedestrian_precision_spcp_vary)\n",
    "\n",
    "pedestrian_fscore_spcp_vary = f1_score(pedestrian_g, pedestrian_spcp_vary, average='samples')\n",
    "print(pedestrian_fscore_spcp_vary)\n",
    "\n",
    "pedestrian_cm_spcp_vary = confusion_matrix(pedestrian_g.ravel(), pedestrian_spcp_vary.ravel())\n",
    "pedestrian_specificity_spcp_vary = pedestrian_cm_spcp_vary[1,1]/(pedestrian_cm_spcp_vary[1,0] + pedestrian_cm_spcp_vary[1,1])\n",
    "print(pedestrian_specificity_spcp_vary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = rpca_spcp_vary(np.transpose(office), lambda0=\"default\", convergenceTolerance=10**(-3), convergenceLog=\"office_spcp_vary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for low-rank frames, sparse frames and binary mask frames\n",
    "\n",
    "for folder in ['..\\\\office_SPCP_VARY_L\\\\', '..\\\\office_SPCP_VARY_S\\\\', '..\\\\office_SPCP_VARY_S_mask\\\\']:\n",
    "    try:\n",
    "        os.stat(folder)\n",
    "    except:\n",
    "        os.mkdir(folder)\n",
    "    filelist = [ f for f in os.listdir(folder)]\n",
    "    for f in filelist:\n",
    "        os.remove(folder + f)\n",
    "        \n",
    "writeImages(\"..\\\\office_SPCP_VARY_L\\\\\", \"office\", L.transpose(), 360, 240)\n",
    "writeImages(\"..\\\\office_SPCP_VARY_S\\\\\", \"office\", S.transpose(), 360, 240)\n",
    "writeMask(\"..\\\\office_SPCP_VARY_S_mask\\\\\", \"office\", S.transpose(), 360, 240, 10)\n",
    "\n",
    "join = map(lambda s: os.path.join(\"..\\\\office_SPCP_VARY_S_mask\\\\\", s), os.listdir(\"..\\\\office_SPCP_VARY_S_mask\\\\\"))\n",
    "office_spcp_vary = generateMatrix(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate F-measure, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13607314439542242\n",
      "0.2749656659033363\n",
      "0.17699813834462955\n",
      "0.1352856560619501\n"
     ]
    }
   ],
   "source": [
    "### Compare masks \n",
    "office_recall_spcp_vary = recall_score(office_g, office_spcp_vary, average='samples')\n",
    "print(office_recall_spcp_vary)\n",
    "\n",
    "office_precision_spcp_vary = precision_score(office_g, office_spcp_vary, average='samples')\n",
    "print(office_precision_spcp_vary)\n",
    "\n",
    "office_fscore_spcp_vary = f1_score(office_g, office_spcp_vary, average='samples')\n",
    "print(office_fscore_spcp_vary)\n",
    "\n",
    "office_cm_spcp_vary = confusion_matrix(office_g.ravel(), office_spcp_vary.ravel())\n",
    "office_specificity_spcp_vary = office_cm_spcp_vary[1,1]/(office_cm_spcp_vary[1,0] + office_cm_spcp_vary[1,1])\n",
    "print(office_specificity_spcp_vary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
